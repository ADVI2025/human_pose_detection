{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f677cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: opencv-python in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: filterpy in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (1.4.5)\n",
      "Requirement already satisfied: scipy in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: matplotlib in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: numpy<2 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: absl-py in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sentencepiece in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: jaxlib in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: jax in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from jax->mediapipe) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: pycparser in d:\\fitz\\fitzpatrick17k-main\\fzenv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python filterpy scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9142c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames extracted: 167\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_video(video_path, target_fps=30, target_size=(1280, 720), background_subtraction=False):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return []\n",
    "\n",
    "    orig_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(orig_fps / target_fps) if orig_fps > target_fps else 1\n",
    "\n",
    "    if background_subtraction:\n",
    "        back_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "        # or\n",
    "        # back_sub = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "    frames = []\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            # Resize frame\n",
    "            frame_resized = cv2.resize(frame, target_size)\n",
    "\n",
    "            # Convert to HSV for color normalization if needed or keep in BGR\n",
    "            # Histogram equalization per channel\n",
    "            frame_yuv = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2YUV)\n",
    "            frame_yuv[:, :, 0] = cv2.equalizeHist(frame_yuv[:, :, 0])  \n",
    "            frame_eq = cv2.cvtColor(frame_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "            # Background subtraction\n",
    "            if background_subtraction:\n",
    "                fg_mask = back_sub.apply(frame_eq)\n",
    "                frame_eq = cv2.bitwise_and(frame_eq, frame_eq, mask=fg_mask)\n",
    "\n",
    "            frames.append(frame_eq)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Example \n",
    "# video_path = r\"D:\\fitz\\fitzpatrick17k-main\\pose\\UCF50\\Drumming\\v_Drumming_g01_c01.avi\"\n",
    "video_path = r\"D:\\fitz\\fitzpatrick17k-main\\pose\\UCF50\\PullUps\\v_Pullup_g01_c01.avi\"\n",
    "\n",
    "frames = preprocess_video(video_path, background_subtraction=True)\n",
    "print(f\"Total frames extracted: {len(frames)}\")\n",
    "\n",
    "# Optionally display first frame for verification\n",
    "if frames:\n",
    "    cv2.imshow(\"Preprocessed Frame\", frames[0])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb68400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f61437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_kalman_filter():\n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    kf.F = np.array([[1, 0, 1, 0],\n",
    "                     [0, 1, 0, 1],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "    kf.H = np.array([[1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0]])\n",
    "    kf.P *= 1000\n",
    "    kf.R = np.eye(2) * 5\n",
    "    kf.Q = np.eye(4)\n",
    "    return kf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca33f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a979fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # def classify_joint_movement(delta_y, angle_velocity, epsilon_y=5, epsilon_theta=2):\n",
    "# #     if delta_y < -epsilon_y and angle_velocity > epsilon_theta:\n",
    "# #         return 'UP'\n",
    "# #     elif delta_y > epsilon_y and angle_velocity < -epsilon_theta:\n",
    "# #         return 'DOWN'\n",
    "#     # elif abs(delta_y) < epsilon_y and abs(angle_velocity) < epsilon_theta:\n",
    "#     #     return 'STATIC'\n",
    "# #     else:\n",
    "# #         return 'TRANSITION'\n",
    "# def classify_direction(delta_y, angle_velocity, epsilon_y=5, epsilon_theta=2):\n",
    "#     \"\"\"\n",
    "#     Classify movement direction based on displacement and angle velocity.\n",
    "#     Returns: 'UP', 'DOWN', or 'NONE'\n",
    "#     \"\"\"\n",
    "#     if delta_y < -epsilon_y and angle_velocity > epsilon_theta:\n",
    "#         return 'UP'\n",
    "#     elif delta_y > epsilon_y and angle_velocity < -epsilon_theta:\n",
    "#         return 'DOWN'\n",
    "#     else:\n",
    "#         return 'NONE'\n",
    "\n",
    "\n",
    "# def classify_motion_state(delta_y, angle_velocity, epsilon_y=5, epsilon_theta=2):\n",
    "#     \"\"\"\n",
    "#     Classify motion state as STATIC or TRANSITION.\n",
    "#     \"\"\"\n",
    "#     if abs(delta_y) < epsilon_y and abs(angle_velocity) < epsilon_theta:\n",
    "#         return 'STATIC'\n",
    "#     else:\n",
    "#         return 'TRANSITION'\n",
    "\n",
    "# Global variable to remember last state\n",
    "last_state = None\n",
    "\n",
    "def classify_joint_movement(delta_y, angle_velocity, epsilon_y=5, epsilon_theta=2):\n",
    "    global last_state\n",
    "    \n",
    "    if delta_y < -epsilon_y and angle_velocity > epsilon_theta:\n",
    "        last_state = 'UP'\n",
    "    elif delta_y > epsilon_y and angle_velocity < -epsilon_theta:\n",
    "        last_state = 'DOWN'\n",
    "    elif abs(delta_y) < epsilon_y and abs(angle_velocity) < epsilon_theta:\n",
    "        return last_state\n",
    "    return \"TRANSITION\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for different body parts: (name, joint triplet IDs)\n",
    "JOINT_TRIPLETS = {\n",
    "    \"right_elbow\": (12, 14, 16),  # Right shoulder, right elbow, right wrist\n",
    "    \"left_elbow\": (11, 13, 15),   # Left shoulder, left elbow, left wrist\n",
    "    \"right_knee\": (24, 26, 28),   # Right hip, right knee, right ankle\n",
    "    \"left_knee\": (23, 25, 27)     # Left hip, left knee, left ankle\n",
    "}\n",
    "\n",
    "def process_joint_movements(image, joint_history, angle_history):\n",
    "    y_offset = 50  # Starting position for text\n",
    "    for name, (A_id, B_id, C_id) in JOINT_TRIPLETS.items():\n",
    "        # Get latest coordinates\n",
    "        if len(joint_history.get(f'joint_{B_id}', [])) < 2:\n",
    "            continue \n",
    "\n",
    "        A = joint_history[f'joint_{A_id}'][-1]\n",
    "        B = joint_history[f'joint_{B_id}'][-1]\n",
    "        C = joint_history[f'joint_{C_id}'][-1]\n",
    "\n",
    "        # Calculate angle\n",
    "        angle = calculate_angle(A, B, C)\n",
    "        angle_history.setdefault(name, []).append(angle)\n",
    "\n",
    "        # Calculate movement parameters\n",
    "        delta_y = B[1] - joint_history[f'joint_{B_id}'][-2][1]\n",
    "        angle_velocity = 0\n",
    "        if len(angle_history[name]) > 1:\n",
    "            angle_velocity = angle - angle_history[name][-2]\n",
    "\n",
    "        # Classify movement\n",
    "        label = classify_joint_movement(delta_y, angle_velocity)\n",
    "\n",
    "        # Display on image\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"{name.replace('_', ' ').title()}: {label} Angle: {angle:.2f}\",\n",
    "            (30, y_offset),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.9,\n",
    "            (255, 0, 0),\n",
    "            2\n",
    "        )\n",
    "        y_offset += 40  # Move down for next label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeac3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define joint index mappings (Mediapipe Pose IDs)\n",
    "ANGLE_JOINTS = {\n",
    "    \"right_elbow\": (12, 14, 16),  # Shoulder, Elbow, Wrist\n",
    "    \"left_elbow\": (11, 13, 15),\n",
    "    \"right_knee\": (24, 26, 28),   # Hip, Knee, Ankle\n",
    "    \"left_knee\": (23, 25, 27),\n",
    "    # \"spine\": (11, 23, 24)         # Left Shoulder, Left Hip, Right Hip\n",
    "    \"left_hip_knee\": (11, 23, 25),     # Left Shoulder, Left Hip, Left Knee\n",
    "    \"right_hip_knee\": (12, 24, 26) \n",
    "}\n",
    "\n",
    "# Colors for each joint label\n",
    "JOINT_COLORS = {\n",
    "    \"right_elbow\": (255, 0, 0),\n",
    "    \"left_elbow\": (0, 255, 0),\n",
    "    \"right_knee\": (0, 0, 255),\n",
    "    \"left_knee\": (255, 255, 0),\n",
    "    \"left_hip_knee\": (255, 0, 255),\n",
    "    \"right_hip_knee\": (0, 255, 255)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a634ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def draw_trajectories(image, joint_history, max_len=20):\n",
    "    \"\"\"Draw trailing lines showing movement history for each joint.\"\"\"\n",
    "    for key, points in joint_history.items():\n",
    "        if len(points) < 2:\n",
    "            continue\n",
    "        color = (0, 255, 255)  # Example trail color: cyan\n",
    "        for i in range(max(0, len(points)-max_len), len(points)-1):\n",
    "            cv2.line(image, points[i], points[i+1], color, 2)\n",
    "\n",
    "\n",
    "def detect_posture(angle_history):\n",
    "    \"\"\"\n",
    "    Will be replaced by classification model\n",
    "    \"\"\"\n",
    "    left_knee_angles = angle_history.get('left_knee', [])\n",
    "    right_knee_angles = angle_history.get('right_knee', [])\n",
    "\n",
    "    if not left_knee_angles or not right_knee_angles:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    left_angle = left_knee_angles[-1]\n",
    "    right_angle = right_knee_angles[-1]\n",
    "\n",
    "    if left_angle > 160 and right_angle > 160:\n",
    "        return \"Standing\"\n",
    "    elif left_angle < 100 and right_angle < 100:\n",
    "        return \"Sitting\"\n",
    "    else:\n",
    "        return \"Transitioning\"\n",
    "\n",
    "\n",
    "def save_csv_log(filename, angle_history, joint_history, status_history):\n",
    "    \"\"\"Save angle, joint positions, and status to CSV file.\"\"\"\n",
    "    with open(filename, mode='w', newline='') as csv_file:\n",
    "        fieldnames = ['frame', 'joint', 'angle', 'x', 'y', 'status']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        frames = len(next(iter(angle_history.values()), []))\n",
    "        for frame_idx in range(frames):\n",
    "            for joint_name in ANGLE_JOINTS.keys():\n",
    "                angle = angle_history.get(joint_name, [None]*frames)[frame_idx]\n",
    "                # Use last known joint b (middle joint) position as example\n",
    "                b_idx = ANGLE_JOINTS[joint_name][1]\n",
    "                pos = joint_history.get(f'joint_{b_idx}', [(None, None)]*frames)[frame_idx]\n",
    "                status = status_history.get(joint_name, [\"\"]*frames)[frame_idx]\n",
    "                writer.writerow({\n",
    "                    'frame': frame_idx,\n",
    "                    'joint': joint_name,\n",
    "                    'angle': angle,\n",
    "                    'x': pos[0],\n",
    "                    'y': pos[1],\n",
    "                    'status': status\n",
    "                })\n",
    "\n",
    "\n",
    "def write_video(output_path, frame_width, frame_height, fps=30):\n",
    "    \"\"\"Return a VideoWriter object for saving output.\"\"\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    return cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93baac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_kalman_filters = {}\n",
    "joint_history = {}\n",
    "angle_history = {}\n",
    "frame_height, frame_width = frames[0].shape[:2]\n",
    "output_video_path = \"output_annotated.avi\"\n",
    "video_writer = write_video(output_video_path, frame_width, frame_height, fps=30)\n",
    "status_history = {joint: [] for joint in ANGLE_JOINTS.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70affa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_23692\\2667697319.py:43: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(kf.x[0]), int(kf.x[1])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "video_path = r\"D:\\fitz\\fitzpatrick17k-main\\pose\\UCF50\\GolfSwing\\v_GolfSwing_g01_c01.avi\"\n",
    "\n",
    "# video_path = r\"D:\\fitz\\fitzpatrick17k-main\\pose\\UCF50\\PullUps\\v_Pullup_g01_c01.avi\"\n",
    "frames = preprocess_video(video_path, background_subtraction=False)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    for frame in frames:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            for idx, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                key = f'joint_{idx}'\n",
    "                x, y = int(lm.x * image.shape[1]), int(lm.y * image.shape[0])\n",
    "\n",
    "                if key not in pose_kalman_filters:\n",
    "                    pose_kalman_filters[key] = create_kalman_filter()\n",
    "                    # pose_kalman_filters[key].statePre = np.array([[x], [y], [0], [0]], np.float32)\n",
    "                    pose_kalman_filters[key].x[:2] = np.array([[x], [y]])\n",
    "\n",
    "                kf = pose_kalman_filters[key]\n",
    "                kf.predict()\n",
    "                # kf.correct(np.array([[np.float32(x)], [np.float32(y)]]))\n",
    "                kf.update(np.array([x, y]))\n",
    "                pred_x, pred_y = int(kf.x[0]), int(kf.x[1])\n",
    "\n",
    "                if key not in joint_history:\n",
    "                    joint_history[key] = []\n",
    "                joint_history[key].append((pred_x, pred_y))\n",
    "\n",
    "            # Process angles & movements (as you have it)\n",
    "            for name, (a_idx, b_idx, c_idx) in ANGLE_JOINTS.items():\n",
    "                if all(len(joint_history.get(f'joint_{i}', [])) >= 2 for i in (a_idx, b_idx, c_idx)):\n",
    "                    a = joint_history[f'joint_{a_idx}'][-1]\n",
    "                    b = joint_history[f'joint_{b_idx}'][-1]\n",
    "                    c = joint_history[f'joint_{c_idx}'][-1]\n",
    "\n",
    "                    angle = calculate_angle(a, b, c)\n",
    "                    angle_history.setdefault(name, []).append(angle)\n",
    "\n",
    "                    delta_y = b[1] - joint_history[f'joint_{b_idx}'][-2][1]\n",
    "                    angle_velocity = angle - angle_history[name][-2] if len(angle_history[name]) > 1 else 0\n",
    "\n",
    "                    label = classify_joint_movement(delta_y, angle_velocity)\n",
    "\n",
    "                    cv2.putText(\n",
    "                        image,\n",
    "                        f\"{name.replace('_', ' ').title()}: {label} {int(angle)}°\",\n",
    "                        (b[0] + 10, b[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                        JOINT_COLORS[name], 2\n",
    "                    )\n",
    "                    status_history[name].append(label)\n",
    "        posture = detect_posture(angle_history)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"Posture: {posture}\",\n",
    "            (30, 30),  # top-left corner\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "            (0, 255, 255), 2\n",
    "        )\n",
    "        # draw_trajectories(image, joint_history)\n",
    "\n",
    "\n",
    "        cv2.imshow('Pose Tracking', image)\n",
    "        video_writer.write(image)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32be237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_23692\\2059409268.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(kf.x[0]), int(kf.x[1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            for idx, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                key = f'joint_{idx}'\n",
    "                x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "\n",
    "                if key not in pose_kalman_filters:\n",
    "                    pose_kalman_filters[key] = create_kalman_filter()\n",
    "                    pose_kalman_filters[key].x[:2] = np.array([[x], [y]])\n",
    "\n",
    "                kf = pose_kalman_filters[key]\n",
    "                kf.predict()\n",
    "                kf.update(np.array([x, y]))\n",
    "                pred_x, pred_y = int(kf.x[0]), int(kf.x[1])\n",
    "\n",
    "                if key not in joint_history:\n",
    "                    joint_history[key] = []\n",
    "                joint_history[key].append((pred_x, pred_y))\n",
    "                # cv2.circle(image, (pred_x, pred_y), 4, (0, 255, 0), -1)\n",
    "\n",
    "            # Process angles & movements\n",
    "            for name, (a_idx, b_idx, c_idx) in ANGLE_JOINTS.items():\n",
    "                if all(len(joint_history.get(f'joint_{i}', [])) >= 2 for i in (a_idx, b_idx, c_idx)):\n",
    "                    a = joint_history[f'joint_{a_idx}'][-1]\n",
    "                    b = joint_history[f'joint_{b_idx}'][-1]\n",
    "                    c = joint_history[f'joint_{c_idx}'][-1]\n",
    "\n",
    "                    angle = calculate_angle(a, b, c)\n",
    "                    angle_history.setdefault(name, []).append(angle)\n",
    "\n",
    "                    delta_y = b[1] - joint_history[f'joint_{b_idx}'][-2][1]\n",
    "                    angle_velocity = angle - angle_history[name][-2] if len(angle_history[name]) > 1 else 0\n",
    "\n",
    "                    label = classify_joint_movement(delta_y, angle_velocity)\n",
    "\n",
    "                    cv2.putText(\n",
    "                        image,\n",
    "                        f\"{name.replace('_', ' ').title()}: {label} {int(angle)}°\",\n",
    "                        (b[0] + 10, b[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                        JOINT_COLORS[name], 2\n",
    "                    )\n",
    "\n",
    "        cv2.imshow('Pose Tracking', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832f34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fzenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
